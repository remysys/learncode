{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('jaychou_lyrics.txt.zip') as zin:\n",
    "  with zin.open('jaychou_lyrics.txt') as f:\n",
    "    corpus_chars = f.read().decode('utf-8')\n",
    "corpus_chars[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_chars = corpus_chars.replace('\\n', ' ').replace('\\r', ' ')\n",
    "corpus_chars = corpus_chars[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_char = list(set(corpus_chars))\n",
    "char_to_idx = dict([(char, i) for i, char in enumerate(idx_to_char)])\n",
    "vocab_size = len(char_to_idx)\n",
    "vocab_size # 1027"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_indices = [char_to_idx[char] for char in corpus_chars]\n",
    "sample = corpus_indices[:20]\n",
    "print('chars:', ''.join([idx_to_char[idx] for idx in sample]))\n",
    "print('indices:', sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_jay_lyrics():\n",
    "  \"\"\"load the Jay Chou lyrics dataset\"\"\"\n",
    "  with zipfile.ZipFile('jaychou_lyrics.txt.zip') as zin:\n",
    "    with zin.open('jaychou_lyrics.txt') as f:\n",
    "      corpus_chars = f.read().decode('utf-8')\n",
    "  corpus_chars = corpus_chars.replace('\\n', ' ').replace('\\r', ' ')\n",
    "  corpus_chars = corpus_chars[0:10000]\n",
    "  idx_to_char = list(set(corpus_chars))\n",
    "  char_to_idx = dict([(char, i) for i, char in enumerate(idx_to_char)])\n",
    "  vocab_size = len(char_to_idx)\n",
    "  corpus_indices = [char_to_idx[char] for char in corpus_chars]\n",
    "  return corpus_indices, char_to_idx, idx_to_char, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "(corpus_indices, char_to_idx, idx_to_char, vocab_size) = load_data_jay_lyrics()\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hiddens = 256\n",
    "# rnn_layer = nn.LSTM(input_size=vocab_size, hidden_size=num_hiddens) # 已测试\n",
    "rnn_layer = nn.RNN(input_size=vocab_size, hidden_size=num_hiddens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 35\n",
    "batch_size = 2\n",
    "state = None\n",
    "X = torch.rand(num_steps, batch_size, vocab_size)\n",
    "Y, state_new = rnn_layer(X, state)\n",
    "print(Y.shape, len(state_new), state_new[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(x, n_class, dtype=torch.float32): \n",
    "  # X shape: (batch), output shape: (batch, n_class)\n",
    "  x = x.long()\n",
    "  res = torch.zeros(x.shape[0], n_class, dtype=dtype, device=x.device)\n",
    "  res.scatter_(1, x.view(-1, 1), 1)\n",
    "  return res\n",
    "\n",
    "def to_onehot(X, n_class):\n",
    "  # X shape: (batch, seq_len), output: seq_len elements of (batch, n_class)\n",
    "  return [one_hot(X[:, i], n_class) for i in range(X.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "  def __init__(self, rnn_layer, vocab_size):\n",
    "    super().__init__()\n",
    "    self.rnn = rnn_layer\n",
    "    self.hidden_size = rnn_layer.hidden_size * (2 if rnn_layer.bidirectional else 1)\n",
    "    self.vocab_size = vocab_size\n",
    "    self.dense = nn.Linear(self.hidden_size, vocab_size)\n",
    "    self.state = None\n",
    "\n",
    "  def forward(self, inputs, state):  # inputs: (batch, seq_len)\n",
    "    # get one-hot vector representation\n",
    "    X = to_onehot(inputs, self.vocab_size)  # X is a list\n",
    "    Y, self.state = self.rnn(torch.stack(X), state)\n",
    "    \n",
    "    # the fully connected layer first reshapes Y to (num_steps * batch_size, num_hiddens),\n",
    "    # and its output shape will be (num_steps * batch_size, vocab_size)\n",
    "    output = self.dense(Y.view(-1, Y.shape[-1]))\n",
    "    return output, self.state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rnn_pytorch(prefix, num_chars, model, vocab_size, device, idx_to_char,\n",
    "                        char_to_idx):\n",
    "  state = None\n",
    "  # output will record prefix plus the generated output\n",
    "  output = [char_to_idx[prefix[0]]]\n",
    "  for t in range(num_chars + len(prefix) - 1):\n",
    "    X = torch.tensor([output[-1]], device=device).view(1, 1)\n",
    "    if state is not None:\n",
    "      if isinstance(state, tuple):  # LSTM, state: (h, c)\n",
    "        state = (state[0].to(device), state[1].to(device))\n",
    "      else:\n",
    "        state = state.to(device)\n",
    "\n",
    "    (Y, state) = model(X, state)\n",
    "    if t < len(prefix) - 1:\n",
    "      output.append(char_to_idx[prefix[t + 1]])\n",
    "    else:\n",
    "      output.append(int(Y.argmax(dim=1).item()))\n",
    "  return ''.join([idx_to_char[i] for i in output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel(rnn_layer, vocab_size).to(device)\n",
    "predict_rnn_pytorch('分开', 10, model, vocab_size, device, idx_to_char, char_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iter_consecutive(corpus_indices, batch_size, num_steps, device=None):\n",
    "  if device is None:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "  corpus_indices = torch.tensor(corpus_indices, dtype=torch.float32, device=device)\n",
    "  data_len = len(corpus_indices)\n",
    "  batch_len = data_len // batch_size\n",
    "  indices = corpus_indices[0: batch_size*batch_len].view(batch_size, batch_len)\n",
    "  epoch_size = (batch_len - 1) // num_steps\n",
    "  for i in range(epoch_size):\n",
    "    i = i * num_steps\n",
    "    X = indices[:, i: i + num_steps] \n",
    "    Y = indices[:, i + 1: i + num_steps + 1]\n",
    "    yield X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_clipping(params, theta, device):\n",
    "  norm = torch.tensor([0.0], device=device)\n",
    "  for param in params:\n",
    "    norm += (param.grad.data ** 2).sum()\n",
    "  \n",
    "  norm = norm.sqrt().item()\n",
    "  if norm > theta:\n",
    "    for param in params:\n",
    "      param.grad.data *= (theta / norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,\n",
    "                                  corpus_indices, idx_to_char, char_to_idx,\n",
    "                                  num_epochs, num_steps, lr, clipping_theta,\n",
    "                                  batch_size, pred_period, pred_len, prefixes):\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "  model.to(device)\n",
    "  state = None\n",
    "  for epoch in range(num_epochs):\n",
    "    l_sum, n, start = 0.0, 0, time.time()\n",
    "    data_iter = data_iter_consecutive(corpus_indices, batch_size, num_steps, device)  # consecutive sampling\n",
    "    for X, Y in data_iter:\n",
    "      if state is not None:\n",
    "        # use detach to separate the hidden state from the computation graph.\n",
    "        # this is to ensure that the gradient computation of the model parameters\n",
    "        # only depends on the small batch sequence read in one iteration (to prevent\n",
    "        # excessive gradient computation costs).\n",
    "        if isinstance(state, tuple):  # LSTM, state: (h, c)\n",
    "          state = (state[0].detach(), state[1].detach())\n",
    "        else:\n",
    "          state = state.detach()\n",
    "\n",
    "      # output shape: (num_steps * batch_size, vocab_size)\n",
    "      (output, state) = model(X, state)\n",
    "\n",
    "      # the shape of Y is (batch_size, num_steps). after transposing and reshaping,\n",
    "      # it becomes a vector of length batch * num_steps, aligning with the output rows.\n",
    "      y = torch.transpose(Y, 0, 1).contiguous().view(-1)\n",
    "      loss = criterion(output, y.long())\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      # gradient clipping\n",
    "      grad_clipping(model.parameters(), clipping_theta, device)\n",
    "      optimizer.step()\n",
    "      l_sum += loss.item() * y.shape[0]\n",
    "      n += y.shape[0]\n",
    "\n",
    "    try:\n",
    "      perplexity = math.exp(l_sum / n)\n",
    "    except OverflowError:\n",
    "      perplexity = float('inf')\n",
    "    if (epoch + 1) % pred_period == 0:\n",
    "      print('epoch %d, perplexity %f, time %.2f sec' % (\n",
    "          epoch + 1, perplexity, time.time() - start))\n",
    "      for prefix in prefixes:\n",
    "        print(' -', predict_rnn_pytorch(\n",
    "            prefix, pred_len, model, vocab_size, device, idx_to_char,\n",
    "            char_to_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note the learning rate setting here\n",
    "num_epochs, batch_size, lr, clipping_theta = 250, 32, 1e-3, 1e-2\n",
    "pred_period, pred_len, prefixes = 50, 50, ['分开', '不分开']\n",
    "train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,\n",
    "                              corpus_indices, idx_to_char, char_to_idx,\n",
    "                              num_epochs, num_steps, lr, clipping_theta,\n",
    "                              batch_size, pred_period, pred_len, prefixes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
